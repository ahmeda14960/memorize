# GPU-based config for memorization evaluation
# Simplified version of the original levanter config

# ---------------------------------------------------------------------------
# Input text ----------------------------------------------------------------
# ---------------------------------------------------------------------------
book_title: "gatsby"
txt_path: "books/gatsby.txt"

# How many tokens are taken as the prompt (first half of window).
prompt_tokens: 50

# Slide the character cursor by this many chars between windows.
cursor_inc_chars: 10

# slice length
slice_length: 2000

# chunk size  
chunk_size: 100

# ---------------------------------------------------------------------------
# Tokenizer ------------------------------------------------------------------
# ---------------------------------------------------------------------------
tokenizer_name: meta-llama/Llama-3.1-8B

# ---------------------------------------------------------------------------
# Model ----------------------------------------------------------------------
# ---------------------------------------------------------------------------
# Path to HuggingFace model (local or HF hub)
initialize_from_hf: "meta-llama/Llama-3.1-70B"

# ---------------------------------------------------------------------------
# Evaluation settings -------------------------------------------------------
# ---------------------------------------------------------------------------
eval_batch_size: 8  # Reduced for 70B model

# Output paths
plot_path: "bar_plot_char_max_pz_70b_gpu.png"
histogram_path: "pz_distribution_histogram_gpu.png"
pz_threshold: 0.0001

# Uncomment for quick debug (evaluates only first N suffix windows)
# max_examples: 100